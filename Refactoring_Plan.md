# Refactoring Plan for the Sandooo MEV Bot

## 1. Migrate to Aave V3 Flashloans (Atomic Funding)

**Objective:** Eliminate reliance on an owner-funded wallet by using Aave V3 flashloans to supply capital for sandwich trades. All legs of the sandwich (front-run and back-run) will execute within **one atomic transaction** using borrowed liquidity.

**Implementation:** Integrate an Aave V3 flash loan into the bot’s Solidity contract. This involves implementing Aave’s flash loan receiver interface and moving the sandwich logic inside the flashloan callback (`executeOperation`). The contract will call the Aave V3 **Pool** contract’s flashLoan function to borrow the needed asset; Aave will then **transfer the funds and invoke our contract’s `executeOperation`**, where we perform the sandwich trades. After executing the trades, our contract must repay the loan plus fee before the transaction ends (Aave will automatically withdraw repayment at the end of the call). We can use Aave’s `flashLoanSimple()` for a single-asset loan (since typically only one asset like WETH or a stablecoin is needed per sandwich). The atomicity is guaranteed: if anything goes wrong (e.g. insufficient profit to repay), the transaction reverts entirely, so no debt remains.

**Key Steps:**

* Write a new function (e.g. `executeSandwichWithFlashloan`) that requests a flashloan from Aave’s Pool for the amount of base asset needed.
* Implement the required `IFlashLoanReceiver` interface, especially the `executeOperation` callback, to receive the flashloan. Inside `executeOperation`, perform the sandwich: use the borrowed funds to front-run the victim’s trade, then execute the victim’s trade, then back-run (sell) to capture profit, all within this function’s execution.
* Before finishing `executeOperation`, approve the Pool contract to pull the owed amount (principal + fee) from our contract, so that Aave can automatically deduct repayment. Any remaining balance after repayment is our profit.
* Ensure that **all operations occur in one transaction** – the flashloan mechanism assures this, since the loan must be repaid in the same transaction or it reverts.

**Caveats:** Flashloans incur a fee (e.g. 0.09% of the amount for Aave V3 by default). Our profit calculations must account for this fee and gas costs so that we only execute when profit exceeds all fees. Additionally, Aave V3 may allow fee-free flashloans for whitelisted borrowers, but we should not assume that – include the fee in all calculations. We must use the correct Aave Pool address for Ethereum mainnet and ensure the asset we borrow is supported by Aave (e.g. WETH, USDC, etc.). During integration, we should carefully test that the flashloan callback (which contains our trading logic) handles failures gracefully – if the sandwich trade fails or yields insufficient output, the code should `revert` to abort the flashloan (which will rollback the entire transaction). This guarantees no partial losses; either the full sequence succeeds and profits, or it aborts with no effect. Finally, using flashloans means the contract no longer needs to hold reserves, so we must remove any code assuming an upfront balance (discussed in section 9).

**Recommended Tools/Libraries:** Use Aave’s published V3 interfaces to interact with the LendingPool (Pool) contract. OpenZeppelin’s **SafeERC20** utilities can help safely handle token transfers (especially repayment approvals) to avoid non-standard ERC-20 issues. We will also use the Aave docs as a reference to implement the flashloan correctly. On the Rust side, no major changes are needed except to adjust how the bot crafts the transaction: now it will call our flashloan-enabled contract function (instead of funding a normal swap). The bot should supply the flashloan parameters (asset address and amount) when calling the contract.

## 2. Expand Supported Tokens (WETH, Stablecoins, and Others)

**Objective:** Broaden the bot’s scope to handle not just WETH-based trades but also popular tokens like **USDT, USDC, WBTC, DAI, LINK, and MKR**. This ensures the bot can sandwich trades involving these tokens as either input or output. The system should dynamically support tokens and fetch their data (addresses, decimals, etc.) at runtime rather than relying on hard-coded constants.

**Implementation:** Refactor the token handling to be **data-driven**. Instead of only using WETH, maintain a list or registry of supported token contracts and their metadata. For example, we can load token addresses for WETH, USDT, USDC, WBTC, DAI, LINK, MKR from a configuration file or an on-chain source. The bot’s config can include known constants (addresses, decimals, possibly the slot indices for balance if needed for simulation – see below). In the existing code, an earlier update introduced USDT and USDC alongside WETH by adding their addresses and storage slots to constants. We will extend this to all target tokens. The design should allow easy addition of new tokens in the future (e.g. reading from a JSON token list or an environment variable).

At runtime, when the bot sees a pending swap, it should be able to identify the tokens involved and load their info. This could involve using an **ERC20 interface** to query token attributes (decimals, symbol) on the fly if not already known. The bot can use `ethers-rs` to call `ERC20.decimals()` and cache the result. We can also integrate a well-known token list (such as Uniswap’s default token list) offline to seed the addresses and decimals of common tokens.

To evaluate sandwich profitability, the bot needs price estimates for these tokens. Implement a **price oracle fallback** system: for instance, use Chainlink price feeds for supported assets as a baseline. If available, a Chainlink oracle can provide an external price for WETH, BTC, DAI, etc., which helps sanity-check the bot’s internal calculations or convert profit to a common unit. If a Chainlink feed is not available for a token (e.g. LINK or MKR have feeds, but if we later add a more obscure token), the bot can fall back to using DEX mid-prices or a trusted on-chain source. The code should be modular so that adding a new token includes specifying how to get its price (Chainlink feed address or “use DEX pools”). This is mostly for off-chain decision making (the on-chain execution doesn’t need price feeds).

**Caveats:** Many tokens (USDT, USDC, etc.) have different decimals (USDT/USDC have 6 decimals, WETH/DAI 18, WBTC 8, etc.). The bot must handle arithmetic carefully respecting each token’s precision. Also, some tokens have quirks: for example, **USDT’s ERC20 implementation does not return a boolean on `transfer`,** which can break naive Solidity code. We should use OpenZeppelin’s SafeERC20 which handles these safely. Similarly, tokens like MKR may have a different `balanceOf` storage slot. In the simulation engine, because we simulate EVM state, we need the correct storage slots for token balances if we pull them directly. The existing code found those slots for WETH, USDT, USDC (as constants); we’ll extend this mapping to WBTC, DAI, LINK, MKR (which we can find via on-chain introspection or known references). A more scalable approach is to have a function that detects the storage slot for the `balanceOf` mapping (for standard contracts this is often slot 0 or 1, but some proxies like USDC use different slots) – however, since our token set is limited and well-known, manual configuration is acceptable for now.

**Recommended Tools/Libraries:** On the Rust side, the `ethers::abi::Token` utilities can help encode/decode calls to ERC20 contracts. Using **ethers-rs** to call `contract.method("decimals", ())` is straightforward for dynamic token support. We might use an external source like **CoinGecko API** or Uniswap’s token list (as a JSON file) to populate token metadata initially. For price oracles, the **Chainlink Data Feed** addresses on Ethereum can be hard-coded for these tokens and accessed via an `AggregatorV3Interface` in solidity or via off-chain calls to `eth_call`. This provides a robust fallback price if needed (for example, if our simulation needs an initial guess of a token’s value in ETH or USD).

## 3. Extend DEX Support (Uniswap V2/V3, Sushiswap, Pancakeswap)

**Objective:** Enable the bot to operate across multiple decentralized exchanges. Currently, the focus has been on Uniswap (V2 and pending V3). We will add support for **Uniswap V3** (if not fully integrated already) and also **Sushiswap (V2)** and **PancakeSwap (V2 and V3)** on Ethereum. (PancakeSwap is primarily on BSC, but they have deployed on other chains in limited form; our architecture will be multi-chain ready, but on Ethereum this could refer to PancakeSwap’s Ethereum deployments if any, or preparatory work for BSC – see section 4 on multi-chain configurability.)

**Implementation:** Abstract the swap execution logic to handle different DEX protocols. We will implement adapters or use existing libraries for each DEX type:

* **Uniswap V2 and its clones (Sushiswap, Pancake V2)**: These use the same function signatures (factory, pair, and router). Sushiswap V2 is a fork of Uniswap V2 with identical interface, so our code for Uniswap V2 can be reused with just different factory/router addresses. We should maintain a mapping of DEX name to the factory and router addresses on each chain (for Ethereum: Uniswap V2, Sushiswap, etc.). The bot can then look up which DEX a given swap is happening on (by matching the router address in the pending tx) and handle it accordingly. For executing sandwiches, we may directly interact with the pair contracts (for Uniswap V2 style, calling `swap` on the pair contract) or via the router’s swap functions. The current contract uses low-level Yul to call the Uniswap V2 pair contract directly for efficiency; we can continue that approach or call the router’s `swapExactTokensForTokens` if simplicity is preferred (though that adds slight overhead). Since we want to support multiple v2-based DEXs, calling pairs directly (using their factory to get pair address) might be more uniform than using different routers.

* **Uniswap V3 and clones**: Uniswap V3 has a different mechanism (concentrated liquidity pools with immutable contracts). We need to integrate V3 swaps, likely by calling the **Uniswap V3 pool contract**’s `swap` function. This requires our contract implement the callback `IUniswapV3SwapCallback` to pay the pool in the token owed after the swap. The bot’s simulation and execution code must be able to determine the correct pool and the parameters (sqrtPriceLimit, etc., which can usually be set to 0 or max values to indicate “swap as much as possible”). We will use Uniswap’s V3 factory to get the pool address for a token pair and fee tier. The integration of V3 was planned by the original author (roadmap update #3) and presumably partially done; we will complete it by ensuring the contract can handle both V2 and V3 swaps. For V3, we may incorporate Uniswap’s official **V3 periphery library** (or use the `amms-rs` library in Rust, see below) for calculating swap amounts if needed. In solidity, we might use the published interface `ISwapRouter` (Uniswap’s router for V3) to perform swaps in a single call, but since we have fine-grained control, interacting with pools directly might save gas.

* **Router-level integration vs direct pool calls:** To keep the contract lean, we might avoid integrating every DEX’s router and instead interact at the pool level for both V2 and V3. For V2, that means calling `UniswapV2Pair.swap`; for V3, calling `UniswapV3Pool.swap`. This requires less contract code (no need to encode function calls to different routers), but our contract must handle providing liquidity to those calls (e.g., transferring token in for V2 swap, handling callback for V3 swap). The current Yul implementation already manually crafts the Uniswap V2 swap call. We will extend it to detect if a swap is V3 and then call V3’s swap accordingly. The bot off-chain can signal which DEX and method to use or we can program the contract function to accept a parameter indicating V2 vs V3 flow.

**Pool discovery:** We need a robust way to find the pools on these DEXes (address and state) for simulation, which is covered in the next section. But for execution, once we know which pool to target, our contract needs the correct address. For V2, given token A and B, we find the pair via `factory.getPair(A,B)`; for V3, via `factory.getPool(A,B, fee)`. We should include the known fee tiers for Uniswap V3 (e.g. 0.3% most common, and possibly 0.05% or 1% for stablecoins). Sushiswap V3 (if it exists on Ethereum) would similarly have a factory and pools, but since it’s relatively new, we may prioritize Uniswap V3 first.

**Caveats:**

* Each DEX integration must account for subtle differences. For example, Uniswap V3 will revert if the output is less than the specified minimum or if the sqrtPrice limit is hit – we must set parameters correctly to avoid unexpected reverts. We’ll set liberal bounds (0 for sqrtPriceLimitX96 to allow full range swaps) and use our simulation to determine acceptable minimum outputs.
* **Gas costs:** Supporting more DEXs means our contract can handle more logic. We should modularize this to avoid one monolithic function handling every case, which could become too large. Perhaps separate internal functions for “execute V2 swap” and “execute V3 swap” called from the flashloan callback depending on the scenario. We must test the combined gas cost of flashloan + multi-swap; it should remain within block gas limit. Using efficient coding (possibly continuing to use Yul for low-level calls) will help.
* **PancakeSwap on Ethereum:** PancakeSwap v2 on Ethereum (if any) would behave like Uniswap V2. PancakeSwap V3 was launched on BNB Chain; if we intend multi-chain support, the architecture will allow configuring a BSC endpoint and Pancake addresses, but on mainnet Ethereum, PancakeSwap isn’t a significant venue. We mention it for completeness and ensure our code can be configured for BSC easily (e.g. via the chain config).

**Recommended Libraries:** To simplify multi-DEX support, we can leverage existing libraries. Notably, **amms-rs** (a Rust crate) provides a unified interface to interact with AMMs across chains, supporting UniswapV2 and V3 among others. We can use this on the Rust side for simulation and pool syncing. It likely includes logic to find pools, calculate swap outcomes, etc., which can reduce our custom code. On the Solidity side, using **Uniswap’s V3 core interfaces** (IUniswapV3Pool, IUniswapV3Factory) will be necessary. We should also use the **Sushiswap factory** ABI for getPair, which is identical to Uniswap’s. According to Messari’s tutorial, since Sushi’s API is the same as Uniswap’s, we can reuse the Uniswap V2 interface for it. We will maintain constants for each DEX’s factory and possibly router addresses in a config module (so the bot knows where to fetch state from and the contract knows where to call).

## 4. Implement Robust Pool/Token Fetching (Discovery & Resilience)

**Objective:** Enhance the system’s ability to discover and fetch data for liquidity pools and tokens in a fault-tolerant way. This includes initially loading all relevant pools, keeping their state updated, and handling errors or restarts gracefully. We also aim to design the system to be multi-chain capable, even if we enable only Ethereum for now.

**Implementation:** We will build a **Pool Discovery and Sync module** in the bot (Rust side) that automatically finds pools on the supported DEXes and keeps track of their state (reserves/liquidity). On startup, the bot will query each DEX’s factory for all pool addresses. For Uniswap V2-style factories, we can use the `allPairs()` and `allPairsLength()` methods to enumerate every pair. For example, Uniswap V2 and Sushi factories allow iteration through all pair indices. This can be slow if done via RPC for thousands of pairs, so a more efficient approach is to use The Graph or another off-chain source to get the list of pairs (Uniswap and Sushi have subgraph endpoints listing all pairs and their reserves). As an alternative, we can hardcode common pairs (like those involving our supported tokens) to limit scope. A balanced approach: fetch all pairs where the base token is one of our supported set (WETH, USDC, etc.) since most sandwiches involve a common base. This dramatically cuts down the number of pools to monitor (e.g. only pairs that include WETH or a stablecoin).

For Uniswap V3, there isn’t a built-in all-pools iterator, so we rely on events (`PoolCreated`) or subgraph data. We will query the Uniswap V3 subgraph to get all existing pools and their fee tiers for tokens of interest. We’ll similarly filter to pools that include at least one of our major tokens to manage scope.

After initial discovery, the bot will maintain these pools in memory. We will implement **state syncing**: periodically (or upon certain triggers) refresh each pool’s reserves/liquidity. This can be done by calling `getReserves()` on Uniswap V2 pairs or reading the slot values directly from our Erigon node’s state. Since we have a local Erigon with tracing enabled, we can use `eth_getStorageAt` or Erigon’s state dump to fetch reserves efficiently. Uniswap V3 pool state (liquidity, current price tick, etc.) can be fetched via `slot0()` call and `liquidity()` call on the pool. We might also subscribe to Swap events in real-time to update reserves incrementally rather than polling.

**Fault tolerance:** The fetching logic will be designed to handle RPC failures or partial data gracefully. For example, if one RPC call times out or returns an error, the bot should catch the error and retry a few times or skip that pool for the moment (mark it for later refresh) rather than crash. We can implement exponential backoff for retries. We will also use multiple data sources when possible: e.g., if the local Erigon is temporarily unresponsive for a query, fall back to a public Infura/Alchemy for that data (given this is a mission-critical system, having a backup RPC provider for reads can increase reliability). However, since Erigon is local and pruned for performance, it should handle queries quickly in most cases.

**Resumption after failure:** We will implement persistence for critical data so that if the bot restarts, it doesn’t need to rediscover everything from scratch. For instance, maintain a local cache file or database of known pool addresses and their last known state. On restart, load this cache and then validate it against current chain state (e.g., check block numbers or a quick reserve check) to update any changes. This way, a restart (or crash recovery) becomes faster. The persistence can be as simple as a JSON file listing all pool addresses for each DEX and maybe their token pairs, updated whenever a new pool is discovered.

**Modular chain configuration:** All the above should be written in a chain-agnostic way. We will create a configuration structure that holds chain-specific parameters: RPC endpoint, chain ID, addresses of factories, addresses of key tokens (for filtering), etc. This allows us to reuse the code for other EVM chains by just switching config. For now, the config will only have Ethereum active, but we’ll include placeholders for BSC (PancakeSwap addresses) or others. The bot could be extended to multiple chains concurrently by running multiple instances or one instance with multiple configs.

**Caveats:** Ethereum mainnet has a very large number of pools (Uniswap V2 \~ thousands, Uniswap V3 a similar magnitude of pool contracts). We likely will not monitor every single pool exhaustively, as many will never be relevant (e.g. obscure token pairs with no volume). Focusing on pools that involve at least one of our supported tokens dramatically reduces the set (because sandwiches typically occur on swaps between a common asset and a target asset). For example, if we support WETH and stablecoins as base, then any swap between two obscure tokens (neither is WETH or a stable) we might ignore for now – the architecture allows adding if needed, but to keep performance manageable, we target the most likely opportunities. This is a design decision to trade completeness for performance. It can be revisited if the bot needs to sandwich, say, a token↔token trade that doesn’t involve our bases (which is rarer and often less profitable due to difficulty in unwinding without a base currency).

Another caveat is keeping state in sync with the mempool. If a large swap happens (the one we target for sandwich), by the time we consider the back-run trade, the pool reserves will have changed. Our simulation engine (section 7) will handle that by simulating the effect of the victim’s trade. But we should also update our cached reserves after executing a sandwich (or seeing one happen) to avoid using stale reserves for the next opportunity. We’ll incorporate events or the results of our simulation to keep the pool cache up-to-date.

**Recommended Libraries:** As mentioned, **amms-rs** in Rust has functionality to **discover, sync, filter, and interact** with AMM pools across chains. We can leverage that to do much of the heavy lifting for pool discovery and syncing. It likely interfaces with the factories and can listen to events (using `ethers-rs` under the hood) to update when new pools are created or liquidity changes. Using such a library can accelerate development and ensure correctness. We will also use **Tokio** for managing asynchronous tasks (calls to RPC) concurrently, with careful handling of timeouts. For persistence, a lightweight database like **SQLite** or just writing to a JSON file can be used; Rust’s `serde` can easily serialize our in-memory data structures to JSON for a quick cache file.

## 5. Build Cross-DEX Arbitrage Engine (Multi-Hop Sandwiching)

**Objective:** Extend the sandwich logic to allow **multi-hop and cross-DEX trades within the same atomic transaction**. This means the bot could, for example, front-run on Uniswap and back-run on Sushiswap (or vice versa) if that yields a better profit, or even perform a sequence of swaps across multiple pools to realize an arbitrage profit path. The route selection should optimize for maximum profit while considering gas and slippage.

**Concept:** Traditional sandwiching keeps both the buy and sell on the same DEX/pool. Cross-DEX arbitrage sandwiching is more powerful: if a user trade pushes the price on DEX A, our bot could buy on DEX A before the user, then after the user’s trade, sell on DEX B where the price is higher (or buy on B and sell on A, depending on the direction of the price discrepancy). Essentially, the bot’s second leg is an arbitrage trade between DEX A and DEX B, triggered by the user’s trade imbalance. Doing this in one transaction captures the price difference before any external arbitrageur can correct it.

**Implementation:** We will generalize the back-run logic to allow using a different DEX than the front-run. The simulation engine will evaluate not just “if we buy and sell in the same pool” but also “if we buy on DEX X and sell on DEX Y, what is the outcome?”. This turns the problem into a route-finding exercise. For each detected victim transaction, we know the token being bought or sold and the amount. Suppose the victim is swapping TokenA -> TokenB on Uniswap. Our options for profit could include:

* Classic sandwich: TokenA -> TokenB -> TokenA on Uniswap (push price up, then down).
* Cross-DEX: TokenA -> TokenB on Uniswap (front-run), then TokenB -> TokenA on Sushiswap (back-run arbitrage). Here, after the victim trade, Uniswap’s price for TokenB is high, Sushiswap’s might be lower (TokenB undervalued on Sushi relative to Uniswap), so selling TokenB on Uniswap yields diminishing returns, but selling on Sushi yields more of TokenA.
* Multi-hop paths: Perhaps go Uniswap: TokenA -> TokenB, then use TokenB to buy TokenC on another DEX, etc., eventually converting back to TokenA. However, multi-hop beyond two exchanges starts to get complex; initially we focus on two-exchange arbitrage.

To implement cross-DEX in one transaction, our flashloan-funded contract can perform multiple swaps in sequence. Thanks to Ethereum’s composability, we can call any number of DEX contracts within our flashloan callback. For example, the contract could:

1. Use flashloan of TokenA (or whatever base asset needed).
2. Swap TokenA for TokenB on Uniswap (front-run).
3. Swap TokenB for TokenA on Sushiswap (back-run arbitrage).
4. Repay flashloan in TokenA, keep the profit.

This is a **multi-swap atomic arbitrage**. It has been demonstrated that executing multiple swaps across DEXes in one tx is feasible – to maximize arbitrage performance, you often need to swap across multiple exchanges within one transaction. We will implement such sequences by extending our contract’s logic to handle two back-to-back swaps. Essentially, after the first swap (front-run) we will not immediately finalize; we will check if a second swap on another DEX is configured and execute that next. The ordering is important: front-run on the same DEX as victim (to manipulate price for the victim) should happen first, victim’s trade happens (in the middle, implicitly, as we position our transactions around it in the bundle), then the back-run arbitrage on the second DEX happens after the victim’s trade. However, within *our* single transaction, we actually execute the second DEX swap immediately after the first – how can this mirror the scenario? The key is that our bundle will include: our front-run tx (calling our contract doing first swap and second swap) **then** the victim’s tx, then possibly another tx of ours. Wait, if we do both swaps in one contract call, the victim’s tx would actually be squeezed in the middle via bundling semantics, which complicates execution flow. We may need to restructure: likely, we should keep the pattern of two separate transactions for sandwich: one tx for front-run, one tx for back-run. In cross-DEX case, the front-run tx interacts with DEX A, the back-run tx interacts with DEX B. These can still both be executed by our contract via two separate function calls, each in its own Flashbots bundle position. But the problem is flashloan: we wanted atomic across the whole sandwich. Ideally, we want the flashloan to cover both legs, meaning both legs happen in one transaction (the flashloan callback). But if both legs are in one transaction, we can’t insert the victim’s trade in between – unless the victim’s trade is included as an internal call, which it isn’t (it’s an independent tx). Therefore, **fully atomic sandwich with flashloan** means our front-run and back-run trades must actually be in the same transaction (so that one flashloan covers both), which implies the victim’s trade is in the middle of our transaction – not possible because one transaction can’t contain another user’s transaction.

This suggests a limitation: a flashloan-based sandwich typically packages the entire sandwich as one transaction (and includes the victim trade via MEV bundle with “revertingTxHashes” if needed). However, an alternative approach: we execute the front-run and back-run as *two separate flashloan transactions*, each independently atomic (this would require splitting the flashloan or having capital). A better approach: use the flashloan for the front-run and hold the acquired tokens (TokenB) in our contract temporarily, **do not repay yet**, then after the victim’s tx (in the next block or same block bundle), use those tokens to do the back-run on another DEX and then repay. But that breaks atomicity across a block boundary.

To maintain atomicity, a possible trick is **bundling two transactions with a dependency**: Flashbots allows marking transactions that can revert without dropping the bundle. We could bundle: flashloan front-run tx (which does first swap and then *pauses*, effectively waiting for second tx?), victim tx, and a second tx that completes the sequence. In practice, it might be easier: we can do a single transaction flashloan that performs both swaps on different DEXes and repay in one go, and include the victim’s tx in between via bundle ordering. The victim’s trade will change the state of DEX A (and possibly DEX B if it also hits B, but usually it’s one DEX). If our contract in one transaction does both swaps back-to-back, it would be assuming the victim’s trade already happened – which it wouldn’t have if our tx executes entirely before victim. So instead, we likely need to do:

* **Tx1**: flashloan, front-run on DEX A, repay flashloan (this must finish before victim).
* Victim’s Tx.
* **Tx2**: flashloan (or use leftover from Tx1) and arbitrage trade on DEX B, repay.

This implies two separate flashloan cycles. That’s not ideal atomicity across the whole sandwich, but each flashloan is atomic on its own. We might accept this and handle that the profit from the first may need to carry into the second. Alternatively, we could **not repay** the flashloan in Tx1, and carry it into Tx2, but that’s impossible since each flashloan must be closed in one tx. Therefore, perhaps the cross-DEX arbitrage could be done in the same block but split into two transactions. This is a complex design decision: fully atomic multi-swap in one transaction is straightforward if no other tx in between, but with the victim in between, we may need to use bundling to simulate the sequence. In an MEV bundle, we *can* have: \[Tx1: our contract with flashloan doing front-run, Tx2: victim, Tx3: our contract doing back-run] all included together. We can allow Tx3 to see the state after victim (because it’s later in the block). However, Tx1 had to repay its flashloan before ending, meaning we gave back funds – we’d need another flashloan or initial capital for Tx3. A solution: maybe do *not repay in Tx1*, by intentionally reverting Tx1 at the end but mark it allowable (Flashbots has a feature to allow intermediate tx to revert without cancelling the whole bundle). For example, Tx1 could take a flashloan, do front-run swap, then fail to repay (which causes revert) – normally that would cancel the bundle, but if we mark it as an allowed revert, the state changes from Tx1 don’t persist except maybe the victim’s tx is unaffected because it runs after. That likely doesn’t help because if Tx1 reverts, it’s as if front-run didn’t happen – not acceptable. So, indeed, cross-DEX sandwich within one block may require holding some inventory across the victim’s trade.

Considering complexity, a simpler approach for now is: **Focus on single-transaction arbitrage where both swaps occur back-to-back (multi-hop) without an intervening victim** – this can capture pure arbitrage but not a sandwich. Or do the sandwich in the same pool atomic, and treat cross-DEX as a secondary arbitrage after the sandwich. Perhaps the intended meaning of "multi-hop sandwiching" is actually **triangular arbitrage within the sandwich**: e.g., front-run by swapping A->B on DEX1, then instead of directly swapping B->A, swap B->C and C->A on other DEXes to complete the loop. This would all be in one transaction around the victim. It’s very complex to coordinate around the victim’s trade ordering.

Given time, we will implement a simpler version: after identifying a victim trade, the bot’s simulation will consider if executing an arbitrage between DEXes *immediately after* the victim yields profit. If so, the bot can attempt to include an additional arbitrage tx in the bundle after the victim. This could mean we do a normal sandwich on the original DEX (front-run and back-run to get base profit) and simultaneously include another trade on a second DEX to arbitrage any remaining price difference. That effectively becomes a **two-part strategy**: the sandwich itself, and a cross-DEX arb as a separate tx. This is easier to implement: the simulation engine just needs to simulate the post-victim state and see if a profitable arbitrage exists, then include it. It’s not exactly “one atomic operation” as the question asks, but it is within one bundle (one block). We will document this approach as an incremental step, with the ideal goal of a truly atomic cross-DEX sequence if feasible in the future.

**Route Selection:** The engine will generate possible “routes” for executing the strategy:

* Route 1: {DEX A front-run, DEX A back-run} (classic sandwich).
* Route 2: {DEX A front-run, DEX B back-run} (cross-DEX).
* Route 3: {DEX A front-run, DEX X intermediate swap, DEX A or B back-run} (multi-hop, e.g., incorporate a third token).
* Possibly more hops.

Each route has an associated gas cost and slippage impact. The engine will compute the end result of each route via simulation (calculating how much of the original asset we end up with). It will subtract the gas fee (gas used \* gas price) and flashloan fee to compute net profit. Then it will choose the route with the highest net profit. We will also include a “do nothing” route (no sandwich) which yields 0 profit, to ensure we don’t execute negative-profit routes.

Optimizing for gas: Multi-hop routes use more gas (more swaps). If two routes yield similar profit but one uses fewer swaps (less gas), the engine should favor the cheaper one. We can incorporate gas cost into the profit calculation directly as mentioned. We’ll also be mindful of not overusing gas – a route that nearly consumes the block gas limit might be impractical even if profit seems high, because it could risk not getting included or outpricing itself.

**Caveats:**

* **Complexity and Reliability:** The more complex the multi-swap sequence, the more points of failure. Each additional pool interaction could revert due to slippage or low liquidity if our amounts are off. We must implement tight slippage controls: e.g., when executing multi-hop swaps, pass `amountOutMin` parameters that ensure if any leg slips beyond profitability, it will revert (better to abort than take a loss). Our simulation should predict outputs conservatively, and we might set `amountOutMin` a bit lower than simulated to account for unforeseen slippage.
* **Timing:** Cross-DEX arbitrage is time-sensitive. We essentially compete with standard arbitrage bots who will also notice a price discrepancy between DEX A and B once the victim’s trade happens. However, by bundling our back-run arbitrage in the same block immediately after the victim, we preclude external arbitrageurs from intervening in that block. This is ideal – it leverages our privileged position in the bundle. We need to ensure our bundle is accepted though (see section 10 on relays and bribing).
* **Profit distribution:** If we perform a multi-hop that yields profit in a different token, ensure we convert it back to the desired asset by the end. For example, if we do A->B then B->C as an arb path, we should end in token A (or whatever token we need to repay flashloan in). Typically we want to end in the asset we flashloaned or our profit asset so we can easily settle and measure profit.

**Recommended Tools:** Use the simulation capabilities of `revm` (discussed later) to evaluate multi-swap scenarios. The **amms-rs** library can also compute multi-hop trades; it supports finding arbitrage across Uniswap V2 and V3 pools. We might use it to identify profitable cross-DEX trade paths. There is also prior research and examples of multi-DEX arbitrage – for instance, Flashbots’ example searcher code suggests backrunning a trade by arbitraging between two exchanges. In Flashbots MEV Share tutorials, they describe: if a user trade moves the price on one DEX, **we'll arbitrage the pair between two exchanges for profit**. We will follow this principle. For implementation in Solidity, the **Solidity Developer’s MultiSwap article** provides a pattern for performing multiple swaps in one transaction. We can draw on that pattern to chain our swaps, adjusting it to our sandwich timing.

In summary, the arbitrage engine will enumerate possible ways to profit from a given opportunity (including cross-market), simulate them, and pick the best route. This route info is then used to construct the actual bundle of transactions (which might be one or two transactions on our part, depending on the design chosen for flashloan usage in cross-DEX). The chosen route will be executed only if the projected profit is significantly positive to cover all costs and a safety margin.

## 6. Enable Massively Parallel Operation (Concurrency & Prioritization)

**Objective:** Redesign the bot’s runtime to handle many tasks in parallel: multiple transaction simulations, opportunity searches, and even multiple sandwich executions concurrently (provided they don’t conflict). We also introduce a system to prioritize which opportunities to execute when resources are limited or when timing is critical.

**Implementation (Concurrency Framework):** We will leverage Rust’s asynchronous programming (Tokio) to achieve parallelism. The bot’s architecture will be divided into producers and consumers:

* **Mempool Listener (Producer):** A component subscribes to the Ethereum node’s mempool (via WebSocket or Erigon’s native txpool feed) to receive new pending transactions in real-time. Each time a swap transaction is detected (e.g., a pending tx calling a known DEX router or pair contract), this is an *opportunity candidate*. Instead of handling it sequentially, we enqueue it for analysis.

* **Simulation Workers (Consumers):** We maintain a pool of worker tasks that take pending opportunities from a queue and perform the heavy simulation and profit calculation (as outlined in section 7). By having multiple workers, the bot can analyze many pending txs at once, utilizing multiple CPU cores. Rust’s Tokio runtime by default will execute tasks on a thread pool, effectively achieving parallel processing (Tokio uses a work-stealing threadpool so that futures can run in parallel across CPU cores). We may also use `tokio::spawn_blocking` for truly CPU-bound simulation tasks (since running the EVM simulation is CPU heavy and might block the async scheduler). We will fine-tune the number of worker threads based on CPU capability (for example, have, say, 4 simulation tasks running in parallel if 4 cores are available, to maximize throughput).

* **Synchronization:** To avoid conflicts, we need to coordinate on certain shared resources. The main conflict scenario is if two pending transactions involve the **same pool or token**. For example, if two users are both swapping in the same Uniswap pool at roughly the same time, and we detect both, we might attempt two sandwiches on the same pool. In reality, only one can be executed in the same block (you can’t reliably sandwich two transactions in the same pool separately if they end up in one block; you might have to bundle them together). To handle this, we will introduce a lock or tracking mechanism keyed by pool or token pair. If a worker is already simulating an opportunity on Pool X, we could temporarily mark Pool X as “busy” and avoid launching a second simulation on the same pool until the first is done or until we decide how to bundle them together. Another approach is to let both simulate, but before execution, detect the conflict and merge or choose one. We will implement a **priority resolver** (see below) that handles such conflicts by choosing the more profitable opportunity or combining them in a bundle if possible (group bundling was an idea the original author implemented to handle multiple sandwiches together).

* **Prioritization:** Not all opportunities are equal; some are far more profitable or urgent (e.g., a very large trade with high profit potential vs a small trade). Also, the bot has a limited capacity of how many bundles it can send per block (due to gas and the risk of competing with itself). We will create a central coordinator task that receives results from simulation workers (each result includes the potential profit, the target block for inclusion, and details of the transaction/bundle to execute). This coordinator will rank the opportunities by **projected profit** (perhaps also profit-per-gas or profit-weighted by probability of inclusion). It will then decide which to attempt to execute. For example, if five profitable sandwiches are found for the next block but executing all five might exceed the block gas or conflict, it might choose the top two or three that are highest profit and non-conflicting. We will also consider **timing sensitivity**: if a certain victim transaction has a very high gas price, it’s likely to be mined sooner – we need to act on it immediately for the next block. If another has a low gas price, it might not be mined for several blocks, meaning we could wait or simulate it more carefully. The coordinator can use the victim tx’s gas price or position in the mempool to estimate urgency. High-priority items get simulated and executed first. Low-priority ones might even be deferred or simulated with lower resource priority.

**Massively Parallel Simulations:** With the above, we can have many simulations in flight. This is crucial because in a busy mempool, multiple swap transactions can come in within the same second. A sequential bot might miss some while busy simulating one. Our parallel design aims to capture as many as possible. For example, if the mempool sees 10 new swaps, we spawn (up to the worker limit) tasks to simulate each. Tokio ensures they run concurrently. We do need to be careful not to overload the system – e.g., simulating 100 at once could spike CPU and cause all to be slow. We will likely implement a **queue limit** and drop or ignore very low-value transactions if the queue is full. That is, if our workers are saturated, we can filter incoming opportunities by a quick heuristic (like skip any swap below X Ether or with too low possible slippage).

**Parallel Execution:** In terms of sending transactions, we could theoretically send multiple sandwiches in the *same block* if they target independent pools. For example, a sandwich on WETH-DAI Uniswap and another on WETH-LINK could both be executed in parallel with no interference. If both are profitable, we should attempt both. Flashbots and MEV relays allow bundling multiple separate bundles, but a miner/builder will include whichever yields them the best combined profit (they might include both if non-conflicting and both pay). We should attempt to submit all high-value bundles. Our coordinator will handle packaging these (see section 10).

**Caveats:**

* We must ensure thread-safe access to shared data (the pool state cache, the mempool queue, etc.). We will use appropriate synchronization (Mutex or RwLock for the pool cache when updating, or design it as mostly immutable snapshots passed to workers to avoid locking during simulation).
* Debugging concurrency can be challenging; we will add extensive logging to trace what the bot is doing in each thread (with identifiers for each opportunity) to catch any deadlocks or race conditions.
* There’s a risk of **over-saturating the block**: if we find too many opportunities, trying to execute all could lead to extremely large bundles that might not all fit in a block gas-wise or could conflict with each other. The coordinator’s job is to prevent that by selecting a reasonable subset. For example, if each sandwich is \~200k gas, and we have 5, that’s \~1M gas – potentially fine. But if we had 20, that’s 4M gas, still under block limit (\~30M), but with other transactions in block it might be unrealistic. However, block builders could include many MEV tx if profitable, so maybe they would. We should still cap for safety or at least ensure the combined gas doesn’t exceed, say, 80% of block gas to leave room for the victim transactions themselves and other stuff.
* Combining multiple sandwiches in one bundle could yield ordering issues or reverts if they share tokens. The group bundling approach (executing multiple sandwiches in one transaction) was noted by SolidQuant, but implementing that is complex. Instead, we likely bundle separate transactions.
* **Memory and CPU**: Running many simulations may increase memory usage (each revm instance with a forked state). We will implement some form of caching (next section) to mitigate repeated state loading overhead, but the concurrency means more memory. We must monitor memory usage to avoid OOM on the host machine (especially if Erigon is also using memory). We can put a cap on number of concurrent simulations to something safe given our hardware.

**Recommended Libraries:** We’ll use **Tokio** for concurrency (with async/await, and possibly channels for queue). The Rust `futures` crate’s utilities or `tokio::sync::mpsc` can implement the task queue. A **priority queue** can be implemented using a binary heap in Rust (the `std::collections::BinaryHeap` can store items with a custom comparator for profit). We might use that in the coordinator to always pick the highest profit item. There are crates like `priority-queue` or we can do it manually. For ensuring only N tasks at a time, Tokio’s **Semaphore** or using a limited size threadpool is useful. We can also use **crossbeam-channel** if we prefer sync channels for simplicity in some parts.

Overall, the parallel framework will significantly speed up opportunity detection and ensure we handle bursts of mempool activity without missing out.

## 7. Optimize Simulation & Profit Calculation (REVM Efficiency and MEV Awareness)

**Objective:** Improve the performance and accuracy of the bot’s transaction simulation engine. This includes caching commonly used state, profiling gas usage for cost estimation, handling block state updates (“fork-aware” simulation), and incorporating MEV-specific considerations like competitor interference (frontrunning/backrunning by others).

**Current Setup:** The bot uses **REVM** (a Rust EVM library) to simulate transactions on a fork of the Ethereum state. This is crucial for predicting the outcome of sandwich transactions without actually executing them on chain. However, naive use of REVM can be slow if we repeatedly load state from the node for each simulation and do not reuse prior computations.

**Performance Optimizations:**

* **State Caching:** We will cache contract bytecodes and storage that are frequently accessed. For example, the bytecode of the Uniswap pair contracts, the token contracts, etc., can be cached in memory after the first load. REVM allows inserting code into its runtime environment. By caching bytecode, we avoid re-fetching it from the node on every simulation. As Paweł Urbanek notes in his REVM tutorial, caching all bytecodes significantly improves performance. We will implement a cache where, whenever REVM tries to load an account’s code or storage, we check if we already have it. If not, fetch once via RPC (using Erigon’s state queries) and store it. Over time, the bot will accumulate the code for all relevant contracts (DEX pools, tokens, etc.). Since our universe of contracts is limited to DEX and token contracts, this is very manageable.

* **Memory reuse:** REVM can be instantiated once and reused for multiple simulations by resetting state in between, rather than creating a new instance every time. We will explore using REVM’s **inspect** mode or snapshot functionality. For instance, we can create a baseline state at the start of a block (reflecting the blockchain state at that point) and then **snapshot** it. For each simulation, clone the snapshot (which is much faster than re-loading state from scratch) and apply the transactions (front-run, victim, back-run) to that cloned state. After simulation, discard the clone. This snapshot mechanism avoids reinitializing the entire state. If REVM itself doesn’t have a built-in snapshot, we can simulate one by keeping a copy of the `StateDB` structure and reusing it.

* **Fork-aware block replay:** By this we mean the simulation engine should be aware of changes in the blockchain state as new blocks come in. Each time a new block is mined, we need to update our base state (the “fork”). For example, if some transactions in the block affected the pools we track, our cached state must be updated. We will handle this by listening to new block events and diffing the relevant state (or simply refetch relevant parts of state after each block). Because we have a pruned node with tracing, we could potentially get a diff of state changes from Erigon. Simpler, we just invalidate caches for any pool that had a swap in the new block (we can detect swaps by events or by checking if reserves changed from our last known state).

* Additionally, being fork-aware means if a victim transaction we targeted in a bundle did not get included (perhaps our bundle didn’t land), that transaction might still be in mempool for the next block. We should *re-simulate* it on the new block state because the state might have moved (e.g., price drift from other swaps or changed basefee affecting gas). Our scheduler will detect if an opportunity persists across blocks and decide whether to try again.

* **Gas profiling:** We will use REVM’s output (it can return the gas used by the simulated execution) to know exactly how much gas our sandwich transaction will consume. This allows precise profit calculation: Profit (in ETH or USD) = (value extracted from victim) – (flashloan repayment + fee) – (gas\_used \* gas\_price). We will incorporate the current gas price (for bundles, effectively the priority fee or coinbase bribe we plan to pay) into this. The bot should dynamically adjust the gas price/bribe it’s willing to pay based on expected profit and competition (discussed in MEV-awareness below). We will profile gas usage not only for final execution but also during simulation to identify hotspots – if simulation itself is slow, we might find which opcodes or contracts are heavy. For instance, Uniswap V3 swap can be heavy due to loop over liquidity ticks. If that is a bottleneck, we might consider using a custom lighter computation for it in some cases, or caching tick data.

* **Parallel simulation with caching:** Combining with section 6, multiple simulations might try to load the same token code simultaneously. We should ensure our caching strategy is thread-safe (perhaps use a concurrent map for bytecodes loaded). Otherwise, each thread might duplicate work. A design is to have a single global state cache that all simulation tasks reference (read-lock for reading cached data, write-lock when fetching new data). This way, once one simulation has fetched the Uniswap pair bytecode, others use it. This will reduce redundant RPC calls drastically. An external measurement suggested such caching and optimizations can cut RPC calls by \~90% while speeding up simulations. This is important for keeping up with mempool flood.

**MEV-Aware Simulation:**

* **Frontrunning resistance:** We simulate under the assumption that our bundle will be included as we want. However, we should consider that another MEV bot might attempt to beat us. In a private relay scenario, if we’re using Flashbots or similar, they won’t see our tx to frontrun it. But if for any reason our transaction leaks to the public mempool, it could be stolen. To be safe, we will not send our transactions to the public mempool at all (always to private relays, see section 10). This mitigates direct competition during the block. However, competition can still occur in that multiple searchers might target the same victim via private channels. The one who offers the higher miner/bribe gets included. We can’t simulate competitor’s actions easily, but we can anticipate that to win inclusion, we might need to sacrifice some profit as a bribe. We will incorporate a strategy where for high-value sandwiches, we allocate a portion of profit to pay the block producer (via gas tip or direct `coinbase.transfer()`). Our profit calc should consider if we raise our gas bid, how it reduces net profit, and find an optimal point. In practice, we might simply set a rule like “pay up to 50% of profit as bribe if needed” – but deciding needed is hard. We could use a reputation or past observation (beyond scope here). Nonetheless, the simulation’s profit number will later be adjusted when building the bundle to include a bribe if we think competition is likely. This is more of an execution concern but ties into simulation in that simulation should allow a margin for this.

* **Backrunning risk:** After our sandwich executes, could someone backrun *us*? For example, if we leave any arb on the table or if we swapped one token to another and that created a new imbalance, another bot might act. Ideally, our plan leaves no profit for others within that block. For instance, if we only did a same-pool sandwich, maybe a cross-pool arbitrager will fix the price difference we caused (but if we did cross-DEX ourselves, we already took that). We simulate as if we alone exploit the victim; we may simulate a scenario where after our bundle, no further profit remains. If our simulation shows that even after our back-run, token prices between DEXes are still out of line (maybe because we didn’t have enough capital to fully clear the arb), that means someone else can grab that. In that case, perhaps we should also take that remaining arb if possible (multi-hop extension). If not, at least be aware that our profit could be slightly less if another arb transaction slips in the same block after us (though in a bundle we control ordering, so if we include the victim and our txs only, no one else can slip in between in that block; others would have to try next block, by which time our profit is secured). So the primary MEV-aware adaptation is ensuring we do as much as possible in the same bundle and pay sufficient bribe to be included.

* **Revert tolerance:** Flashbots bundles allow specifying certain tx hashes that are allowed to revert without dropping the whole bundle. We can use this feature in simulation and execution planning. For example, we might simulate with a very tight slippage setting that yields profit. If during actual execution the outcome is slightly worse (maybe due to minor differences in state), our transaction could revert. If we mark it as allowed to revert, the bundle would still include the victim’s tx (so the victim gets mined) and our reverted tx would simply not execute, meaning we miss the profit but also incur no loss (except opportunity). This is a safety mechanism. We should simulate the nominal scenario, but also consider using this feature: essentially, we promise a bundle where our tx can fail without harming the bundle, so builders are fine including it. We should then bias our simulation to slightly optimistic knowing that if it doesn’t work out, it just reverts. However, relying on reverts is not ideal; it’s better to simulate accurately and set safe parameters. Still, in code, we will integrate the ability to mark our transactions as “revertible” in the Flashbots API if needed to avoid situations where a small deviation causes the whole bundle (including victim) to be dropped (which could anger the user or waste an opportunity). This is a nuanced MEV strategy which our planning will accommodate.

**Fork-aware Simulation & Replay:**

* We will integrate with the new block event loop such that at each block, we update REVM’s base state. If some simulations were in progress and a new block comes, those simulations’ results might be invalid if the victim was mined or state changed. We’ll cancel or redo those as needed.
* We will also use the **Erigon debug tracer** as a backup: for example, Erigon’s `debug_traceCall` could simulate a transaction with a given state without us manually managing state. But since we already use REVM in-process, we likely stick to that for speed and avoid RPC overhead. However, it’s worth noting that a parity between our REVM simulation and actual Ethereum state is crucial. Erigon is an execution client we trust; REVM is an independent EVM implementation. We should test on a variety of scenarios to ensure REVM yields the same result as the real EVM (particularly for edge cases like certain opcodes or the specific behavior of token contracts). The team patched REVM via foundry-evm-mini in the original code, presumably for accuracy or performance adjustments. We will ensure to use a well-tested version of REVM (the latest or the same commit the project used to avoid regressions).

**Recommended Tools:**

* **REVM**: continue using it, but possibly update to the latest version if it has improvements. The patching they did suggests maybe customizing memory limits or EIP settings; we’ll maintain those as needed.
* **Alloy**: The blog by Urbanek mentions Alloy as a successor to ethers-rs for handling state and forks. We might consider using **Alloy’s fork capabilities** which could have a more optimized pipeline for pulling state. If time permits, we could experiment with Alloy to see if it simplifies some caching. But this may not be necessary if REVM is working well.
* **Criterion** (Rust benchmarking) in development to profile simulation function and optimize hotspots (not in production code, but to tune it).
* Logging and metrics: include counters for number of RPC calls made, average simulation time, etc., to verify the \~90% reduction claim after implementing caching. This will inform if our optimizations are effective.

In summary, by caching state and being smart about how we simulate, we’ll drastically speed up the bot’s ability to evaluate opportunities, which is key to not missing fast-moving MEV chances. We’ll also account for MEV competitiveness by potentially sacrificing some profit as needed to secure inclusion and by making sure our simulation doesn’t assume we’re alone in the universe when we’re not.

## 8. Ensure Extreme Robustness (Defensive Coding & Edge Cases)

**Objective:** Make the system highly resilient to errors, unexpected conditions, and edge cases. Both the Rust bot and the Solidity contract should handle adverse scenarios gracefully, without funds loss or crashes. We aim for a production-grade reliability where issues like transaction reverts, race conditions, or token quirks do not bring down the system or cause unhandled exceptions.

**Defensive Rust Coding:**

* We will audit every `.expect()` or `.unwrap()` in the code and replace them with proper error handling. The bot should not panic on a minor error (like failing to fetch a pool state once). Instead, return an `Err` up the call stack or log it and continue. For example, if a simulation fails due to a rare REVM error or a state missing, catch that, log the details for debugging, and skip that opportunity (or retry after refreshing state).
* Implement timeouts for external operations. If an RPC call to Erigon hangs or takes too long, the bot should not stall indefinitely on it. We can use `tokio::time::timeout` around any external future. If a timeout occurs, we mark that component (e.g., a particular pool’s data) as unavailable and possibly try an alternate strategy (or skip the opportunity if we absolutely need that data).
* Use concurrency primitives wisely to avoid deadlocks. For example, if we use a global mutex for state cache, ensure that no awaited call inside the lock can lead to trying to lock again (to avoid self-deadlock). We might use more granular locks or lock-free structures (like an atomic or RwLock) where appropriate.
* **Retry logic:** For operations that can be transiently unreliable, implement retries. This applies to network calls (RPC) and maybe transaction submission if we don’t get a response from a relay. For instance, if fetching a token’s storage slot fails, try up to 3 times with a short delay. If a flashbots submission returns an error (like “bundle not included”), perhaps we try sending to a different relay or adjust parameters and resend in the next block (if victim still pending). We have to be careful with retries to not duplicate actual on-chain actions; primarily this is for off-chain tasks and sending to relays (which are idempotent in the sense of just offering the bundle).
* **Alerting:** Incorporate an alert system (the original code had optional Telegram alerts). We can extend this such that if critical errors happen repeatedly (e.g., failing to connect to relays, or simulation errors), the bot notifies the operator. This doesn’t directly improve robustness, but ensures issues are flagged immediately to be fixed.

**Defensive Solidity Coding:**

* The contract should check invariants and inputs carefully. For example, as seen in the Yul code, it checks `require(msg.sender == owner, "NOT_OWNER")` on calls – we will maintain that to prevent unauthorized usage. We’ll add similar checks for any new functions (like a dedicated function to initiate flashloan or execute a swap).
* Use OpenZeppelin’s libraries where possible: **SafeERC20** for token transfers (to handle tokens like USDT that don’t return bool), and possibly **ReentrancyGuard** if needed. However, note that in our contract, we *will* have reentrant calls by design (Uniswap V3 pool calls back our contract). We will structure the contract to handle this safely. For instance, the callback function (for Uniswap V3) will be in the same contract. We must ensure it can distinguish a legitimate callback (from a Uniswap pool during our execution) versus a rogue external call. We can do `require(msg.sender == expectedPoolAddress)` in the callback to ensure it’s only called by the pool we’re interacting with. This prevents unwanted reentrancy. We won’t use a global ReentrancyGuard lock if it interferes with our needed callback flow.
* **Edge cases in execution:** Consider token transfers failing or returning funny values. We will double-check that every `transfer` or `transferFrom` returns true or we handle the false/no return. If any swap returns an unexpected amount (perhaps due to fee-on-transfer tokens which reduce the amount received), our contract should not proceed incorrectly. For example, some tokens burn a fee on transfer; if we flashloan 100 and only 98 arrives to our contract, our computations might be off. We could detect such differences by reading balances before and after or by expecting such tokens (maintain a list of known problematic tokens and adjust strategy, or simply factor in a small safety margin on amounts).
* **Preventing stuck funds:** The contract ideally should not hold any funds after execution (profit is immediately sent out). But if for any reason it ends up holding tokens (maybe a leftover dust amount of a token), we want the ability to recover it. We will include an emergency withdraw function for the owner that can transfer out any ERC20 token or ETH held by the contract. This will be protected by `onlyOwner`. This is just a safeguard for unexpected scenarios where tokens get stuck (e.g., if a transaction reverted after taking flashloan but before sending profit, though then it would revert entirely – so perhaps stuck funds could come from someone accidentally sending tokens to our contract address).
* Ensure the contract cannot be tricked into giving out funds: Because we plan to remove any fund holding logic, the main risk is low. But if we allow owner to withdraw, ensure only owner can. If the contract gets ETH (maybe someone sends ETH to it for whatever reason), having a withdraw covers that too (even though we won’t normally handle ETH in our trades, flashloans will likely be in ERC20s like WETH not raw ETH).

**Race Conditions & State Consistency:**

* In concurrency, as mentioned, ensure one opportunity doesn’t double-execute. We might implement a global map of `active_victims` or `active_pools` that the coordinator marks when it decides to execute an opportunity, so any duplicate detection of the same victim tx or same pool is ignored. For example, if two mempool events for the same tx come (maybe via two sources), ensure we don’t process twice.
* Another race scenario: If the victim cancels or edits their transaction (e.g., they replace it with a higher gas or different amount), our simulation might be invalid. We should monitor if the pending tx gets dropped or changed. If the victim’s nonce is replaced with a different tx, drop the old opportunity. This can be done by tracking by tx hash and also by account nonce. Erigon’s txpool might inform of re-org in mempool. If not, we can on each new block check if a targeted tx is still pending or was replaced.

**State Rollback:**

* In simulation, we inherently do rollback by discarding the cloned state. The wording “state rollback” likely also refers to making sure if we partially apply changes in memory or in any persistent storage, we revert them on failure. For instance, if we optimistically update our pool cache after simulating a trade, but then the trade didn’t happen (because our bundle failed), we should rollback that cache update to not mislead future calcs. We can avoid applying simulation results to cache until the bundle is confirmed mined. Alternatively, apply then correct if not mined. It might be simpler to only update cache on actual on-chain events (from block data) and not from simulations.
* On the Solidity side, atomic execution and flashloan inherently ensures state rollback on failure (any revert undoes partial state changes). We just need to ensure to revert when something is off rather than proceeding incorrectly.

**Testing Edge Cases:** We will test with various scenarios:

* Very low liquidity pools (to see if our calculations handle extreme price impact).
* Tokens with transfer fees or non-standard behavior (to ensure SafeERC20 catches it).
* Victim trades that are themselves weird (like a victim doing a multi-hop swap via a DEX router – our parsing needs to decode that and simulate properly).
* Multi-victim scenarios (two big trades in same block in same pool).
* Out-of-gas simulation (if our simulation indicates our back-run might hit the gas limit, we should probably skip that opportunity to avoid a revert on chain).
* The system under high load (simulate a burst of 100 tx and see that the bot stays stable).

**Recommended Practices:** We’ll incorporate many best practices from OpenZeppelin and others for secure contract coding: checks-effects-interactions pattern (in our contract, do checks first like require owner, then effects like updating any state, then interactions like calling external swaps). In our case, most external calls are to well-known contracts (Uniswap, Aave), which are non-reentrant for our context (Aave flashloan calls us instead of vice versa after we call them, which we handle; Uniswap V3 calls us which we handle with checks). We will also limit any `delegatecall` or `callcode` usage (likely none needed besides standard external calls).

By being paranoid in our coding approach, we ensure the bot can run 24/7 without manual intervention, and if something goes wrong, it fails safe (e.g., a transaction just doesn’t execute, rather than the program crashing or funds being lost). Robustness is crucial since real money is at play in MEV bots.

## 9. Smart Contract Refactor (Lean Architecture & Security)

**Objective:** Refactor the Solidity smart contract to streamline it for our new flashloan-based design, remove any unnecessary components (like funding/holding logic), and ensure it has minimal attack surface and trusted assumptions.

**Current vs New:** The existing `Sandooo.sol` (written partly in Yul) was designed to accept funds from the owner (WETH) and use them for sandwiches. It likely maintained an owner and had a fallback function that executed swaps when called by the owner. In the new design:

* The contract **will not hold permanent funds**. It will only temporarily hold flashloaned assets during execution. Therefore, we can eliminate any deposit or withdrawal functions for the owner that were used to top up the contract. The profit will be sent out automatically to the owner’s address at the end of execution.
* We will still keep an **owner address** (set at deploy or via constructor) which represents our bot’s controlling account (or a designated profit receiver). This owner will be the only one allowed to trigger the contract to execute sandwiches (enforced by require checks) and to withdraw any accidental stuck funds.
* **Lean architecture:** The contract will essentially consist of:

  * State variables: owner, perhaps addresses of some known tokens or the Aave Pool (though we can also hardcode Aave Pool address to save gas).
  * The flashloan execution function (which calls Aave’s pool). This might be a function like `executeSandwich(address tokenIn, address tokenOut, uint amountIn, DEX routes…)` which triggers flashLoan and contains the logic to be executed in `executeOperation`.
  * The `executeOperation` callback function (from Aave’s flashloan interface) where the swapping happens. Because this function is called by Aave, we have to trust Aave’s contract to call it and no one else; to be safe, we can `require(msg.sender == AAVE_POOL_ADDRESS)` inside it.
  * Within `executeOperation`, our sequence of Uniswap/Sushi swaps in the correct order (as determined by off-chain logic via parameters).
  * Possibly separate internal functions for performing a Uniswap V2 swap vs Uniswap V3 swap to keep code tidy, which can be called from executeOperation depending on inputs.
  * The Uniswap V3 swap callback function (`uniswapV3SwapCallback`) to handle that when we do v3 swaps. This will use stored variables or parameters to know how much to pay.
  * An `onlyOwner` modifier for relevant functions (we can implement this require(owner == msg.sender) as seen in the Yul snippet).
  * An emergency withdraw function (onlyOwner) to transfer any ERC20 or ETH out.

We will remove any state that is not absolutely necessary. For example, if the old contract stored WETH balance slot or such info, we drop that. The contract doesn’t need to store token balances or other dynamic data; it can query them when needed (or rely on context: e.g., it knows how much it borrowed, and it can compute profit as leftover after repayment).

**Profit Forwarding:** After executing the swaps, ideally we hold some amount of profit in one of the assets (likely the same asset we flashloaned, e.g. WETH or a stablecoin, since we would design the trade to end up with surplus of the borrowed asset). We then do a simple transfer of that profit to the owner address. For instance, if we borrowed 100 WETH and end up with 105 WETH after the sandwich, we repay 100 + fee (\~100.09) to Aave, leaving \~4.91 WETH. We then transfer that 4.91 WETH to the owner. The contract ends with zero balance (except maybe dust due to rounding). By not accumulating funds in the contract, we minimize risk (there’s nothing sitting in the contract to steal over time). Each run extracts profit and immediately sends it out.

We will set the owner’s address as a constant or immutable so that it cannot be changed (unless we want to allow an updateOwner function, but that introduces risk if someone obtains owner key, etc.; probably not needed if we just set it to our wallet).

**Minimize Trust and Permissions:**

* Only the owner can call the function to initiate a flashloan (so no one else can trigger our contract to do a sandwich). If someone else tried, `NOT_OWNER` require will revert, so they can’t misuse our contract. This is important because our contract might have approvals to spend tokens (we will approve Uniswap routers/pairs to spend our tokens inside flashloan context). We don’t want an attacker to call our contract and cause it to spend our tokens in an unintended way. The owner check prevents that entirely.
* The contract itself doesn’t need to approve others to take its tokens except:

  * Approving Aave pool to take repayment (which we’ll do during execution for the exact amount).
  * Approving Uniswap V2 routers/pairs if we plan to call their swap functions that pull tokens. But if we call pair.swap directly and we send tokens with transfer, we might not need an approve. In Uniswap V2, the pair contract will transfer from our contract if we are *outputting* a token to it. However, in practice, for a sandwich front-run, we take flashloan of TokenA and need to swap to TokenB. If calling pair.swap, we need to transfer TokenA to the pair first (as seen in Yul code) rather than pair pulling it. They did exactly that: manually did token transfer to pair, then called swap. This avoids needing an approve. We can continue this pattern to minimize approvals on V2.
  * For Uniswap V3, the pool pulls the tokens in the callback by requiring us to transfer. Actually, in V3, our callback function is supposed to transfer the owed amount of input token to the pool. That again doesn’t require an approve; we just use IERC20 transfer in the callback. So in ideal design, we might not need any persistent approvals to external contracts, which is great for security.
* Remove any admin functions that aren’t needed. Sometimes contracts have things like setFee or toggleFeature – we likely have none of those or won’t add them. Simplicity is safety.

**Huff/Yul vs Solidity:** The current contract is in Yul (possibly for gas optimization). We can continue with Yul for performance, but refactoring major logic (like adding Aave flashloan) in Yul could be time-consuming and error-prone. It might be safer to rewrite parts in Solidity for clarity and then optimize. A hybrid approach: use Solidity for overall structure and only use inline assembly for critical tight loops or calls if necessary. Given gas is important, we may gradually optimize. For initial correctness, a solidity implementation might suffice (the gas cost of a flashloan sandwich, maybe \~300k gas, is dominated by external calls rather than contract’s own instructions, so a small overhead for using Solidity is acceptable).

**Testing the Contract:** We will deploy it on a testnet or mainnet fork and simulate flashloan scenarios to ensure:

* It properly restricts access (calls from non-owner fail with NOT\_OWNER).
* Flashloan lifecycle works: Aave calls executeOperation and we repay correctly.
* Swaps execute and profit is sent out.
* No funds left behind, and emergency withdraw can retrieve if we intentionally send some tokens to it.

**Caveats:**

* If the contract has to handle multiple tokens in one execution (say a multi-hop involving 3 tokens), it may temporarily hold those. It should ideally swap everything back to the flashloan token at end. But if, for example, our profit ends up partly in another token, we should convert it. It’s simplest to always design the strategy such that profit is in the same asset as flashloan or another desired asset. If not, the contract might need a mechanism to convert, say, TokenB profit to TokenA before sending to owner. This could be an extra swap (costly if small amount). We could flashloan both assets, but Aave allows multiple assets in one flashLoan call (V3’s flashLoan can do multi-asset). We could use that if needed, but likely unnecessary if we plan well.
* We should be cautious that **Aave V3 flashLoan** requires either full repayment or it will revert – no partial. So our contract must guarantee the borrowed amount + fee is available at end. We will enforce that with a require check comparing our balance of the asset to the required amount (to avoid an accidental underpayment scenario).
* We want to minimize any on-chain storage writes (for gas). The owner address and perhaps a couple immutables are fine. We should avoid writing to storage in each execution (so no counters or anything that increments per sandwich, as that costs gas each time). We don’t really need such storage; logging can be done via events if needed (we might emit an event on profit for monitoring, but that’s optional and costs gas – probably skip to save gas since off-chain we know profit from our simulation anyway).

By refactoring with these principles, we end up with a slim contract that does exactly what’s needed for the flashloan sandwich and nothing more, making it easier to audit and less likely to have vulnerabilities.

## 10. Multi-Relay Transaction Submission (Broadcaster to Flashbots, Eden, bloXroute)

**Objective:** Increase the chance our bundles are included by broadcasting to multiple MEV relays/networks. Instead of relying solely on Flashbots, we will integrate with other private relay services such as Eden Network and BloXroute (and any others like Blocknative or Manifold). This mitigates the risk of a single relay being a bottleneck or if a validator is not listening to that relay.

**Implementation:** We will enhance the bot’s transaction sending component to support **parallel submission to multiple endpoints**:

* **Flashbots Relay:** We already have `ethers-flashbots` in use which likely handles sending a bundle to Flashbots. Post-merge (PoS), Flashbots runs an MEV-Boost relay. The API for searchers is via `mev_sendBundle` or `eth_sendBundle` with builder specification. We will ensure our code is updated to the latest Flashbots API. The Flashbots service itself can forward to multiple builders if we specify (Flashbots docs mention a `builders` parameter to target multiple builders at once). We should leverage that: e.g., include all known builders (Flashbots, Blocknative, Eden, BloXroute, Manifold) in the `builders` field when using Flashbots API. This way a single call to Flashbots can propagate our bundle to all listed builders (multiplexing) if Flashbots supports it. According to their docs, they do support multiplexing to multiple builders.
* **BloXroute Relay:** BloXroute offers an API (both HTTP and WebSocket via their BDN) to submit bundles. They even allow bundling for Flashbots through their gateway. We may integrate directly with BloXroute’s API as well, especially if we want redundancy. For example, after sending via Flashbots, we can also send via BloXroute’s `blxr_submit_bundle` which will forward to BloXroute’s builder and optionally Flashbots’ builder too. Using BloXroute might require an API key and possibly subscription, but presumably we have or can get one.
* **Eden Network (now part of MEV-Boost as an alternate relay):** We’ll find the endpoint for Eden’s relay. Eden’s relay likely has a similar interface to Flashbots. In fact, with MEV-Boost, searchers typically don’t send directly to each relay; instead, builders use relays to send blocks to validators. But searchers can send bundles to relays via their provided endpoints (some relays like Blocknative have a UI or API, Flashbots we know, BloXroute we know, Eden likely similar).
* **Others:** If Blocknative’s relay (Manifold, etc.) have open APIs, we should include them.

Practically, since Flashbots now provides an API to target multiple relays at once, we may simply use that feature. E.g., when calling `mev_sendBundle`, we include `builders: ["flashbots", "bloxroute", "eden", "manifold"]` in the params. This requires an update to the `ethers-flashbots` provider or using the raw JSON RPC call because older libraries might not have the multiplex parameter. We can always fall back to constructing our own JSON RPC payload using `serde_json` and sending it via an HTTP client or using `Provider::request` in ethers.

We will implement a **RelayManager** in the bot:

* It takes the signed bundle (set of txs and block target).
* It attempts to send it through various channels. We do it concurrently to minimize latency. (Alternatively, because Flashbots can do it for all, we might just do one call.)
* We will also incorporate a fallback to public mempool if all else fails *and* if the scenario allows (though typically we avoid public to not be sniped). Perhaps for very low-value opp, or if relays consistently fail, public could be a last resort with a very high gas to attempt to get in normally. This is risky, so perhaps not unless we are desperate; by default, we can skip public to avoid risk of getting our tx copied by a bot.

**Mempool propagation (Rust-side):** If we ever choose to send to public, we’d use the Ethereum JSON-RPC `eth_sendRawTransaction`. To increase propagation speed, we could send it to multiple nodes (our Erigon, plus maybe an Infura or Alchemy, etc.). BloXroute’s BDN can also propagate to public mempool faster than normal (that’s one of their selling points). But again, we prefer private to avoid competition.

**Bundle Construction:** Our code will take the victim’s raw transaction (from mempool) and our own signed transactions (front-run and back-run) and package them with a target block (usually current\_block+1). We include timing constraints (e.g., only valid for next 2 blocks to avoid being mined later). We’ll also use the feature to allow reverts for certain txs if needed (Flashbots param `revertingTxHashes`). This will ensure if, say, the back-run fails but front-run succeeded, the bundle can still go through with front-run revert or vice versa depending on strategy (only if we intend it, carefully considered as mentioned).

We should also consider **multiple tries**: If a bundle isn’t picked in one block (no builder included it), we may resubmit it for the next block (especially if victim still pending). Many searchers do this – they keep resubmitting until the victim is gone. We implement that: keep track of bundles awaiting inclusion and resubmit (with updated block numbers and maybe adjusting gas price if needed).

**Caveats & Potential Issues:**

* **Relay API differences:** Each relay might have slight differences in how they accept bundles or what they consider. Using Flashbots’ multiplexing abstracts it, but if that’s not reliable, we may do direct calls. We will thoroughly test on mainnet (in a dry-run mode if possible, or via simulation with a local MEV-boost node).
* **Trust:** These relays are generally trusted not to leak our transactions. Using multiple relays slightly increases the surface area of trust (e.g., sending to both Flashbots and BloXroute – we assume both won’t leak). So far their reputations are okay. It’s a trade-off: more relays means more eyes, but also means if one builder has significantly better chance to win a block, we want to be there. Given the competitive landscape (Flashbots usually has majority of blocks, but others also win some), it’s worth risking a bit to not miss out. We’ll proceed with multiple, as requested.
* **Rate limits:** Flashbots and others have rate limits on submissions. If we spam too many bundles, we might get limited. We’ll implement some back-off if we get rate limit errors. Typically though, we will only send a bundle when an opportunity arises, which is not an insane frequency (maybe a few per block at most).
* **Identification:** Flashbots requires an “auth key” (an Ethereum key to sign the payload for identification). We have one (the `identity_key` in env config). We should use the same for others if needed or have separate. BloXroute requires an API key token in the header for their WS/HTTP. We’ll manage those secrets securely in our config (.env).

**Multi-Relay Testing:** We’ll test by sending a dummy bundle (or a very low value bundle) to ensure it reaches the relays. Perhaps attempt on testnet if those relays operate there (Flashbots works on mainnet and maybe Goerli, BloXroute likely on mainnet only for MEV). We might do a dry run with a real transaction that we don’t mind being mined (like an arbitrarily low profit one) to see if it lands via each relay.

**Recommended Libraries/Tools:**

* **ethers-flashbots** (if updated to support builders param). If not, perhaps use **mev-share-rs** (Flashbots’ Rust client library for MEV-Share, which may include bundle sending; but MEV-Share is more about partial info, we might stick to direct).
* Use raw **reqwest** or **ureq** to call BloXroute’s endpoint with our JSON as shown in their docs example.
* Possibly use **web3.js** via Node if needed (but better to do all in Rust for simplicity).
* Keep connections persistent if possible (like a persistent WebSocket to BloXroute’s gateway to send bundles quickly). But overhead of opening HTTP per block is fine too given low frequency.

By diversifying relay submission, we aim to maximize inclusion probability. If Flashbots builder doesn’t pick our bundle, maybe BloXroute’s builder or Eden’s builder will, depending who wins the block. We just need one to include it. Also, if one relay is down or congested, others fill in.

Finally, after execution (if our bundle gets mined), we will confirm which relay mined it (we can see in block extra data or from the relay API responses). We might log that for analysis, perhaps noticing patterns (e.g., if BloXroute got it in, meaning Flashbots missed it, etc.). This could help adapt strategy (like if we see Flashbots ignoring small bundles, maybe increase bribe or rely on others, etc.).

In conclusion, the multi-relay broadcasting will significantly strengthen the bot’s reliability in capturing MEV opportunities in the wild west of Ethereum’s proposer-builder ecosystem by not putting all eggs in one basket.

---

**Sources:**

1. Aave V3 Flashloan mechanism – describes how flash loans transfer funds and call the contract’s callback in one atomic transaction, with no collateral needed as long as funds are returned.
2. SolidQuant’s stablecoin update – explains expanding beyond WETH to USDT/USDC for sandwiches, making the system more flexible with multiple base currencies.
3. AMM interaction library support – confirms a Rust library exists supporting Uniswap V2 and V3, which we can use to streamline multi-DEX integration.
4. Messari tutorial on Uniswap/Sushi arbitrage – highlights using factory’s `allPairs()` and `getPair()` to discover pools on Uniswap and Sushi.
5. SolidityDeveloper on multi-swap arbitrage – emphasizes that maximum arbitrage performance often requires swapping across different DEXes in one transaction.
6. Flashbots documentation on backrun arbitrage – notes that after a user trade moves price, a searcher can arbitrage between two exchanges for profit (the principle behind cross-DEX back-run).
7. REVM performance tips – outlines techniques like caching bytecode to improve simulation speed and reports a 90% reduction in RPC calls with such optimizations.
8. Excerpt from Sandooo’s Yul contract – shows the contract requiring the caller to be the owner, a practice we’ll continue for security.
9. BloXroute bundle submission example – demonstrates how a bundle can be sent to both Bloxroute and Flashbots simultaneously via their gateway API, illustrating multi-relay submission.
