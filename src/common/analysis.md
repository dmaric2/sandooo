# Root Cause Analysis and Solutions for Bot Malfunction

## Issue 1: Bot Detects Very Few Swap Events

**Root Cause:** The transaction classification logic is too narrow, causing the bot to miss most swaps. In `classifier.rs`, a transaction is only labeled as a `Swap` if the target address is in a known router list or if the 4-byte function signature matches a known swap function. Any swap via an **unknown DEX router or aggregator** falls through to the default case and gets classified as `Other`. For example, in the logs the bot classified a swap transaction as `Other` even though it involved a Pepe swap (an unrecognized aggregator address `0x25d887...`). This means the bot’s swap detection relies on an outdated or incomplete list of DEX addresses and function selectors, causing legitimate swaps to go undetected.

**Solution:** Broaden and modernize the swap classification mechanism:

* **Update Known DEX Lists:** Add missing router addresses and swap function selectors to the bot’s known sets. For instance, include addresses for popular aggregators (1inch, 0x, Paraswap, MetaMask swap contract, etc.) and any new Uniswap forks. Also add any unique swap function signatures these use. The code already contains a list of selectors (e.g. Uniswap V2/V3, 0x `sellToUniswap`, 1inch `swap`, etc.), but it should be extended to cover the address/method used by the aggregator at `0x25d887...` and others not originally included.
* **Dynamic Detection:** Implement a fallback check on the contract code of the transaction’s target address. If an address isn’t in the known router set, the bot can retrieve its bytecode or call a known method (like `token0()`/`token1()`) to determine if it’s a liquidity pool or router contract. For example, if `tx.to` isn’t a known router but the contract has a `token0()` function, it’s likely a Uniswap-like pool – classify it as a swap. This catches direct pool interactions and unknown router contracts.
* **Don’t Rely Solely on Hard-Coding:** The classification should be more flexible. Consider using an external registry or configuration for known DEX addresses so it can be updated without code changes. In summary, by expanding the router/signature lists and adding a code-based heuristic, the bot will correctly flag more swap events instead of mislabeling them as “Other.”

## Issue 2: `extract_swap_info` Function Always Returns "0 items"

**Root Cause:** Because of the misclassification above, the `extract_swap_info` routine often finds no swaps and returns an empty list. In the code, `extract_swap_info` first uses `classify_transaction`. If the transaction is not initially classified as a swap, it attempts a **debug trace** to catch internal swap events. However, if the Ethereum provider doesn’t support debug tracing (e.g. Infura/Alchemy without debug API), this call yields nothing. As a result, `extract_swap_info` ends up with **“0 items”**. Even when `classify_transaction` correctly returns `Swap`, there is another logic gap: the function *skips* the trace in that case but might not properly decode the swap. For instance, a transaction to an unknown aggregator with a recognized swap function could be marked as `Swap` but still produce no output because the code doesn’t handle aggregator internals. In short, the function fails to identify swaps due to missing tracing data and lack of input decoding for complex transactions.

**Solution:** Improve `extract_swap_info` by handling more scenarios and ensuring it captures swaps:

* **Enable/Use Debug Tracing:** If possible, run the bot on an Ethereum node that supports `debug_traceCall` (e.g. Geth with debug API, Erigon, or Anvil). This will allow the fallback logic to retrieve internal swap events. In the trace, internal DEX pool events are logged, which `extract_swap_info` uses to find pool addresses. In our log, once a trace was available, the bot successfully found 2 swap events in a complex transaction. Ensuring the trace is available will turn those “0 items” into actual swap info.
* **Parse Known Router Calls:** Implement direct decoding for transactions sent to known routers. If `is_router` is true, parse the transaction input data using the router’s ABI. For example, for Uniswap V2 router calls like `swapExactTokensForTokens`, decode the `path` array of token addresses. Using the path, you can infer the pairs involved (each adjacent token pair in the path corresponds to a pool). Look up those pool addresses in the pool map (or compute them via factory if necessary) and record them as swap info. This avoids relying on a debug trace for standard router swaps.
* **Trace Unknown Swap Contracts:** Modify the logic to handle aggregator contracts that are classified as `Swap` but not in the router list. Currently, the code only triggers `debug_trace_call` when `tx_kind != Swap`. Change this condition to also trace **unrecognized swap contracts**. For example, if `tx_kind == Swap` but `is_router == false` and `is_pool == false` (meaning an aggregator or unknown DEX), still perform the debug trace to extract internal swaps. This ensures even if the transaction was flagged as a swap by a known selector, the internal swaps aren’t missed.
* **Robust Error Handling:** If `debug_trace_call` fails (returns error or None), log a clear warning and consider returning an error from `extract_swap_info` (currently it prints an error but might still return Ok(empty)). By making these changes, `extract_swap_info` will more reliably return a list of swap details instead of empty, even for complex transactions.

## Issue 3: Bot Operates with Very Few Pending Transactions

**Root Cause:** The bot is overly restrictive in which pending mempool transactions it keeps for analysis. After classifying a pending transaction, the code decides whether to add it to the `pending_txs` map based on certain criteria (e.g. gas price vs. base fee). The log `should_add: true` indicates this check, which likely skips transactions with too low a max fee. If this threshold is miscalculated or too high, the bot will ignore most pending swaps. Additionally, if `extract_swap_info` finds no swap (returning 0 items), the code does **not add** that transaction to `pending_txs`. This means only transactions deemed promising (with at least one swap identified) are tracked. In the observed behavior, because swap detection was failing (issue 1 & 2), almost no transactions were being added – hence the bot saw only a handful of pending txs.

**Solution:** Relax the filtering and ensure more potential swaps enter the pipeline:

* **Fix Gas Price Threshold:** Re-examine the `should_add` logic for pending transactions. Make sure it compares the transaction’s gas price (or max fee) against the current base fee correctly and uses the same units. If the bot erroneously marked `0.8343 Gwei` as sufficient (`should_add: true` for a likely too-low fee), it suggests a potential unit mix-up or a very low base fee scenario. Align this check with real network conditions (e.g., require `max_fee_per_gas >= current_base_fee` for EIP-1559, and perhaps some margin for priority fee). Conversely, don’t set the bar so high that legitimate swaps with slightly low fees are skipped – they might still get mined in a later block, and the bot could profit if prepared.
* **Add All Detected Swaps:** Whenever `extract_swap_info` finds swap pairs, add the transaction to `pending_txs` immediately. (The code already does this when items > 0, as seen in the log.) The key is to improve detection (from issues 1 & 2) so that more transactions reach this point. Once classification is fixed, the number of pending txs in the bot’s memory will naturally rise, since it’s no longer discarding real swaps as “Other”.
* **Consider Temporary Tracking:** As an enhancement, the bot could tentatively store transactions that *might* be swaps even if not fully confirmed. For example, if `classify_transaction` returns `Swap` but `extract_swap_info` fails due to lack of trace, you might still keep it in a temporary list and re-process it when a new block arrives (some swaps might become evident if included in a block). This is an advanced tweak to avoid missing opportunities due to timing.
  By adjusting these filters, the bot will monitor a larger set of pending swap transactions, improving its chances to spot sandwich opportunities.

## Issue 4: `classify_transaction` Function Always Returns "Other"

**Root Cause:** The classification function is not recognizing swap transactions, defaulting to `Other` for almost everything. As discussed in Issue 1, the lists of known routers and selectors are incomplete. For example, the Pepe swap transaction was marked as `Other` because its target address `0x25d887...` wasn’t in `ROUTER_SET` and its function selector wasn’t in `SWAP_SELECTOR_SET`. The code’s design is such that any transaction not explicitly matched falls into the `Other` category. This explains why **“classify\_transaction always returns Other”** – the conditions for the other categories (Eth transfer, ERC20 transfers/approvals, or Swap) are rarely met given new DEX contracts and methods. Essentially, the classification logic lagged behind the evolving DeFi landscape.

**Solution:** Enhance `classify_transaction` to correctly identify swaps:

* **Expand Known Patterns:** Incorporate the latest known router addresses and swap method signatures into the code. For instance, if using Uniswap v3’s new Universal Router or other aggregator contracts, add their addresses to `ROUTER_SET` and any unique function selectors to `SWAP_SELECTOR_SET`. In the code snippet, several selectors for 1inch (`0x12aa3caf` for `swap`), 0x (`0xd9627aa4` for `sellToUniswap`), etc., are already present. Verify if there are new ones to include (e.g., 1inch v5 `unoswap`, or any specialized flashswap functions). Keeping these lists updated will directly reduce the frequency of `TxKind::Other`.
* **Use Code-Based Identification:** As mentioned earlier, implement checks based on contract bytecode. For example, if `tx.to` is not None and not in the known set, fetch the code via `provider.get_code`. If the code size corresponds to a Uniswap V2 pair (the bytecode size of a UniswapV2Pair is known) or contains the function signatures of a pool, then classify as `Swap`. Similarly, if the code matches a router pattern (e.g. Uniswap V2 router bytecode has specific characteristics), classify accordingly. This approach catches swaps involving contracts the bot hasn’t seen before.
* **Testing and Tuning:** After modifications, run the classifier on a variety of recent transactions (including known swaps and non-swaps) to ensure it labels them correctly. The goal is to see `TxKind::Swap` for any transaction that interacts with an AMM or DEX. With these improvements, `classify_transaction` will no longer “always return Other” – it will correctly categorize many more transactions as swaps, which is essential for the rest of the bot’s logic to trigger.

## Issue 5: `appetizer` Always Reports "promising sandwiches: 0"

**Root Cause:** The appetizer stage never finds any sandwich opportunities, always outputting zero. This is a direct consequence of the prior issues: if hardly any pending swaps are being tracked and analyzed, there are no “victim” transactions to sandwich. In the one case where swaps were detected (the Pepe transaction), the simulation still aborted due to missing pool reserves (Issue 6), so no sandwich was recorded. Essentially, **the pipeline fails before appetizer** – by the time the code calls `appetizer`, the input list of promising swaps is empty or the simulation fails. The log confirms this: after processing a pending swap, it prints `promising sandwiches: 0`, indicating that none of the detected swaps were deemed sandwichable (often because they were skipped due to errors). Another subtle cause could be overly strict profit or slippage thresholds in the simulation (making it report no opportunity even if one exists), but given the pervasive detection issues, the primary reason is that valid candidates never make it through.

**Solution:** Fixing the earlier issues will largely resolve this, but there are specific improvements for the appetizer phase as well:

* **Propagate More Swaps to Appetizer:** Implement the solutions from Issues 1–4 so that by the time `appetizer()` runs, the `pending_txs` map is filled with actual swap transactions (now correctly classified and enriched with `SwapInfo`). With a richer set of pending swaps, the appetizer can finally evaluate sandwich opportunities. Expect the log to start showing non-zero counts (e.g., “promising sandwiches: 3”) once multiple pending swaps are being simulated each block.
* **Improve Simulation Robustness:** The appetizer uses `BatchSandwich::simulate` to evaluate profitability. We saw in the log that a simulation was attempted but failed due to missing reserves. It’s important to ensure the simulation doesn’t abort entirely when one pool’s data is missing. Wrap reserve fetching in error handling that **skips only the problematic pool** instead of the entire transaction. For example, if a multi-hop victim trade uses two pools and one pool’s reserves can’t be fetched, the code could still attempt a sandwich on the other pool (or at least log that one pool was skipped while continuing with others). Currently, a reserve failure leads to skipping the sandwich altogether. Improving this flow will allow the appetizer to find opportunities even if one data source fails.
* **Tune Opportunity Criteria:** Double-check the conditions that determine a “promising sandwich.” These might include minimum profit, gas cost considerations, etc. If they are set too high, the bot might be discarding viable sandwiches. As part of refactoring, log more details in appetizer: for each potential sandwich, log the expected profit or outcome. This transparency will help adjust the thresholds so that real opportunities are not mistakenly filtered out.
  After these fixes, the appetizer component should start reporting some promising sandwiches (assuming the mempool has sandwichable trades). You should see log lines like “DEBUG: Found X promising sandwiches” instead of constant zeros, indicating the bot is finally identifying targets.

## Issue 6: Bot Consistently Fails to Retrieve Pool Reserves

**Root Cause:** The bot’s simulation fails to get liquidity pool reserves, especially for certain addresses. The logs show repeated warnings for a specific pool address (0x6982508145454Ce3... in the example) where both Uniswap V2 and V3 reserve fetch calls reverted. Notably, that address is actually the **Pepe token contract**, not a liquidity pool at all. This reveals a bug in how the bot identifies pools. In this case, the bot mistakenly treated the Pepe token as a pool address (likely because it was present in the `pools_map`). Consequently, when trying to call `getReserves()` on it, the token contract reverted (it doesn’t implement that function), and the fallback `get_v3_pool_reserves` also failed (it’s not a v3 pool either). This indicates flaws in the pool discovery/loading logic: either the pool list contains incorrect entries (token addresses or other non-pool contracts), or the bot is failing to distinguish which addresses from a swap trace are actual pool contracts. It might also suggest that Uniswap v3 pools are not pre-loaded in `pools_map`, causing real v3 pool addresses to be missing and leading to reserve fetch failures. In summary, the reserve retrieval fails because **the bot is querying the wrong addresses or has incomplete pool data.**

**Solution:** Correct the pool mapping and reserve access logic to reliably retrieve reserves:

* **Clean up the Pool Database:** Audit how `pools_map` is built. If it’s using on-chain events, ensure the code properly parses the pool address from factory events (e.g., the `PairCreated` event). Any logic that adds an entry to `pools_map` should be reviewed. For example, if a CSV of pools is used, verify its contents and format. Remove any entries that are not actual pool contracts. In our case, having the Pepe token address in the pool map was a mistake – the loader might have mis-parsed something. Make sure only addresses that have legitimate `token0`/`token1` and reserve data are kept. One way to validate is to call `token0()` and `token1()` on each address when loading; if the call fails or returns zero addresses, skip that entry.
* **Incorporate Uniswap V3 Pools:** If the bot intends to sandwich Uniswap v3 trades, include those pools in the map as well. Uniswap V3 pools don’t emit a `PairCreated` event, but they do emit a `PoolCreated` event from the factory. Extend the pool loading to capture v3 pools by listening for `PoolCreated(token0, token1, fee, tickSpacing, pool)` events from the v3 factory. Alternatively, query a reliable source (like a subgraph or known list) for popular v3 pool addresses. Add these to `pools_map` with `DexVariant::UniswapV3`. This will prevent reserve fetch failures for v3 swaps. Currently, the code has a fallback to calculate v3 reserves by fetching `slot0` and `liquidity`, but that only works if the pool address is known and the contract code is accessible. By populating v3 pools in advance, `get_v3_pool_reserves` can succeed when invoked.
* **On-Demand Pool Detection:** As a safety net, implement on-the-fly pool recognition during swap extraction. When `extract_swap_info` identifies a log address that isn’t in `pools_map`, the bot can query that contract’s `token0/token1`. If it responds, dynamically register it as a new Pool (with the correct Dex variant). This ensures even if a new pool was created after the initial load (or was missed), the bot can still fetch its reserves.
* **Handle Reserve Fetch Failures Gracefully:** Despite all precautions, if a reserve call still fails (e.g., a pool is temporarily unresponsive or uses a non-standard mechanism), catch that error and **skip that pool** without terminating the entire sandwich simulation. The log spam of repeated failures suggests the bot retried the same bad call multiple times; instead, it should mark that address as unusable and move on. For instance, if `get_pair_reserves` reverts, do *one* fallback to `get_v3_pool_reserves`. If that also fails, log a one-line warning and do not attempt that address again for this transaction. The simulation can then continue evaluating other swap hops or simply not include that pool’s portion. This way, a single problematic pool (or token mistaken as pool) won’t derail the whole sandwich attempt.
  After these fixes, reserve retrieval should succeed for the vast majority of legitimate pools. In the Pepe case, the bot will correctly identify the WETH-PEPE Uniswap pair (rather than the Pepe token) as the pool and fetch its reserves. The warnings about reserve failures will disappear, and the bot will use the obtained reserves to calculate sandwich profits accurately.

## Refactoring Steps to Fix the Bot

To implement the above solutions, follow these step-by-step changes in the codebase:

1. **Expand Swap Classification (classifier.rs):**

   * Update the `ROUTER_SET` and `SWAP_SELECTOR_SET` with any missing DEXes or aggregators. For example, add the address `0x25d887ce7a35172c62febfd67a1856f20faebb00` (from the logs) to the router set if it corresponds to a known aggregator, and include its function selector in the swap selectors. Also add other common router addresses not present (e.g., 1inch v5, Paraswap) and their selectors.
   * In `classify_transaction()`, after the existing checks, add a new fallback: if `tx.to` exists and wasn’t identified, attempt to fetch the contract code or call a known method. Pseudocode:

     ```rust
     if tx_kind == TxKind::Other {
         if let Some(addr) = tx.to {
             if is_uniswap_pool_code(&provider, addr).await { 
                 return TxKind::Swap; 
             }
         }
     }
     ```

     Implement `is_uniswap_pool_code` to call `token0()` on the address; if it returns two valid addresses, consider it a Swap (it’s a pool). Similarly, you might detect known router bytecode patterns. This change will reduce false “Other” classifications.
   * **Testing:** Run unit tests or new tests on `classify_transaction` with sample transactions (you can use real swap tx data) to ensure the outputs are as expected (Swap, EthTransfer, etc.). All swaps from popular venues should now return `TxKind::Swap`.

2. **Enhance extract\_swap\_info (simulation.rs):**

   * Change the logic that decides when to use `debug_trace_call`. Currently, it traces only if `tx_kind != TxKind::Swap`. Modify this so that **unhandled Swap cases also trigger tracing**. For example:

     ```rust
     if tx_kind != TxKind::Swap || (tx_kind == TxKind::Swap && !is_router && !is_pool) {
         // perform debug_trace_call as fallback for unknown swap internals
     }
     ```

     This ensures that if a transaction is marked Swap but the bot has no direct way to parse it (not a simple router or pool call), it will still capture internal events.
   * Implement input decoding for known routers inside `extract_swap_info`. When `is_router` is true, use the router’s ABI to decode the transaction input. Identify the `path` (for Uniswap V2/V3) or list of pools (for aggregators if available) and populate the swap info vector with those pool addresses. For Uniswap V3’s `exactInput` or `exactOutput` calls, decode the embedded path which encodes multiple hops. This might involve splitting the byte sequence into token addresses and fee values. Leverage ethers-rs ABI decoding to assist with this.
   * After decoding, log the discovered swap pairs for verification (e.g., `debug!("Decoded pools: {:?}", swap_info_vec)` ). This will help confirm that the function is now extracting the correct swap details instead of returning 0.
   * **Testing:** Use a known multi-hop swap transaction (e.g., WETH -> USDC -> PEPE) and run it through `extract_swap_info`. Verify that the returned vector contains the correct pool addresses (e.g., WETH-USDC pool and USDC-PEPE pool) and that the count matches the number of hops. Also test a single-hop router swap and a direct pair swap.

3. **Adjust Pending TX Filtering (streams.rs or strategy.rs):**

   * Review how `should_add` is calculated when receiving a `PendingTransaction` event. Ensure that it’s using the current base fee (`new_block.base_fee`) correctly. If the comparison is `max_fee < base_fee`, consider also the `max_priority_fee`. A safer check is:

     ```rust
     let max_fee = tx.max_fee_per_gas.unwrap_or(tx.gas_price);
     let base = new_block.base_fee;
     should_add = max_fee >= base;
     ```

     If this was a units issue, correct any misuse (both values should be in Wei).
   * To allow more transactions, you can lower the bar: for example, include transactions that are slightly under the base fee (they might get mined if the base fee falls). Perhaps `should_add = max_fee >= 0.8 * base_fee` as a heuristic. Document this threshold and make it configurable if possible (so you can tweak without code changes).
   * Remove or loosen any additional gating. For instance, if there is logic skipping transactions already seen or those without swaps, that’s fine, but ensure that after fix #2, most swaps are recognized. Essentially, once `extract_swap_info` yields a non-empty vector, the code already adds the tx to `pending_txs`. The key here is to trust the improved detection and not filter out too aggressively.
   * **Testing:** Run the bot connected to a live Ethereum node for a short time and monitor how many pending transactions it accumulates. You should see a significant increase. Compare the pending count before and after this change under similar network conditions.

4. **Fix Pool Discovery and Data (pools.rs and related):**

   * In `load_all_pools()` (or wherever pools are imported), add verification for each pool entry. After creating a `Pool` struct, do a quick call via the provider: e.g., `provider.call(token0(), at pool.address)`. If this call fails or returns an unexpected value (0x0 address), skip writing this pool to the cache/map, as it’s likely invalid. This will filter out entries where the pool address was wrong (such as token addresses).
   * If not already in place, implement loading of Uniswap V3 pools. Use the known Uniswap V3 factory (address `0x1F98431c8aD98523631AE4a59f267346ea31F984`) to get `PoolCreated` logs. Parse those logs to get `token0`, `token1`, `fee`, and `pool` address. Create `Pool` structs with `DexVariant::UniswapV3` and store them. This may be complex to do from scratch; as an alternative, consider manually seeding the bot with important v3 pools (WETH-USDC 0.05%, WETH-USDT 0.3%, etc.) if focusing on major tokens.
   * Ensure `pools_map: HashMap<H160, Pool>` is used consistently. After loading, the map size should reflect unique pool contracts (check the count vs. expected number of pools for Uniswap and other DEXes). If the count is extremely large (hundreds of thousands), make sure they truly are unique addresses and not duplicate factories. If duplicates were found (as might happen if using only event signature without address filter), refine the log filtering to use known factory addresses. For example, only accept `PairCreated` events where `log.address` equals one of the known factory addresses (UniswapV2, Sushi, etc.). This prevents random contracts that emitted a similar event from polluting the list.
   * **Testing:** After reloading the pool list with the new method, pick a few addresses at random from `pools_map` and verify they are real pools (e.g., check on Etherscan or via `provider.get_code` that code exists and has Uniswap bytecode). Also ensure the Pepe token address (0x6982... in our case) is no longer present in the map as a key. If it is, trace through how it got added and adjust the filtering further.

5. **Improve Reserve Fetching (evm.rs & simulation.rs):**

   * In `EvmSimulator::get_pair_reserves`, handle error results more gracefully. The current implementation logs a warning and bubbles up the error. Instead, you can catch the error at a higher level (in the sandwich simulation loop). For example, in `BatchSandwich::simulate`, wrap the reserve calls in a `match` or `if let Err` and on failure, mark that pool as unusable. You could maintain a boolean flag like `reserve_ok = false` for that pool’s SwapInfo and later skip any sandwich logic for it, while still trying others. The key is to continue the loop over `swap_info_vec` instead of breaking out entirely when a reserve fetch fails.
   * When a reserve call fails for a supposed Uniswap V2 pool, double-check if the address might actually be a Uniswap V3 pool. If so, perhaps the code should have called `get_v3_pool_reserves` initially. This scenario should be resolved by step 4 (correct DexVariant in Pool). But as a sanity check: if `getReserves` reverts and you catch the error, you might decide to **try identifying the contract type on the fly**. For instance, call `token0()` – if it works but `getReserves` doesn’t, that’s a clue it might be a v3 pool, so call `get_v3_pool_reserves`. (Your current code already does a v3 fallback if `DexVariant` is v2 and the call failed, which is good. The issue was that the address wasn’t a pool at all.) So the main change is to avoid repeating these calls once they’ve failed and move on.
   * If a pool’s reserves are missing, log a concise warning (e.g., “Skipping pool X due to missing reserve data”) instead of a full stack trace. The current output is very verbose, possibly due to using `anyhow` errors. You can either handle the error before it propagates with `?` (thus avoiding a backtrace print) or ensure the warning is printed only once. This will make the logs cleaner and focused on actionable information.
   * **Testing:** Simulate a scenario with a known problematic address. For example, use the Pepe token case: inject a SwapInfo with a fake “pool” = Pepe’s address, and run `BatchSandwich::simulate`. It should now log one warning and continue rather than spamming and marking the whole bundle as failed. More realistically, run the bot again on a live net: when a sandwich attempt is made, see that if one pool fails, the bot either tries the next or at least doesn’t crash the attempt. Ultimately, with the pool list corrected, every identified pool should return reserves successfully, and these warnings should rarely appear.

6. **Verify Sandwich Detection End-to-End:**

   * With all the above refactorings, run the bot in a controlled environment (e.g., against a mempool feed or a forked network) to verify that it now goes through the full cycle: detects a swap, adds the pending tx, simulates the sandwich, and if profitable, would proceed to bundle submission (the latter part wasn’t in scope of the question but is the final step of the strategy). Check the log output for something like:

     * “Initial classify\_transaction: Swap” (instead of Other).
     * “extract\_swap\_info returned X items” with X > 0.
     * “Added transaction to pending\_txs” (pending count rising).
     * “promising sandwiches: Y” where Y is the number of profitable scenarios found (could still be 0 occasionally, but not always).
     * No errors or warnings about reserves for valid pools (those should be fixed).
   * If any of these are not meeting expectations, iterate on the relevant step above. For example, if some swaps still show up as `Other`, add their signatures to the classifier and redeploy. Or if `promising sandwiches` is still 0 but you see swaps are detected, inspect the profit simulation parameters. The refactoring steps aim to address the structural problems; after this, it may be about fine-tuning parameters to actually execute sandwiches.

Following all these refactoring steps will turn the bot into a fully functional state. It will detect many more swap events, correctly identify the pools involved, maintain a healthy list of pending victim transactions, and successfully simulate sandwich attacks (retrieving pool reserves without errors). Each issue from 1 to 6 will be resolved, allowing the bot to proceed from monitoring the mempool all the way to launching profitable sandwich transactions.
